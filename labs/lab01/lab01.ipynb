{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 80: Lab 01\n",
    "\n",
    "### Due Date: Saturday October 10, Midnight (11:59 PM) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zoom Lab Hours\n",
    "- Follow instructions on this link: https://docs.google.com/document/d/16qZpPSYhxwQDMcn-lGQjC-J-PzppLevv_mANLt2ko8g/edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding work will be developed in an accompanying `lab01.py` file, that will be imported into the current notebook.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying python file will be tested (a la DSC 20),\n",
    "2. The notebook will be graded (for graphs and free response questions).\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Tips for working in the Notebook**:\n",
    "- The notebooks serve to present you the questions and give you a place to present your results for later review.\n",
    "- The notebook on *lab assignments* are not graded (only the `.py` file).\n",
    "- Notebooks for PAs will serve as a final report for the assignment, and contain conclusions and answers to open ended questions that are graded.\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `.py` file.\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional functions to solve the lab! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `lab01.py` (much like we do in the notebook).\n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing code from `lab**.py`\n",
    "\n",
    "* We import our `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab**.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab**.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab**.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab**` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab01 as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 0 (EXAMPLE):**\n",
    "\n",
    "Write a function that takes in a possibly empty list of integers and:\n",
    "* Returns `True` if there exist two adjacent list elements that are consecutive integers.\n",
    "* Otherwise, returns `False`.\n",
    "\n",
    "For example, because `9` is next to `8`:\n",
    "```\n",
    ">>> lab.consecutive_ints([5,3,6,4,9,8])\n",
    "True\n",
    "```\n",
    "Whereas:\n",
    "```\n",
    ">>> lab.consecutive_ints([1,3,5,7,9])\n",
    "False\n",
    "```\n",
    "\n",
    "*Note*: This question is done for you, to demonstrate a completed homework problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop your code here (or in an IDE) if you'd like.\n",
    "# Though only code in lab01.py will be graded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add more cells if you'd like!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your code in two ways:\n",
    "1. Run the cell below to test your code. You should also copy the cell and change the input to test further (i.e. write your own doctests)! Does it work for corner cases? Real-world data is **very messy** and you should expect your data processing code to break without thorough testing!\n",
    "2. Run doctests on `lab01.py` by running the following command on the commandline:\n",
    "```\n",
    "python -m doctest lab01.py\n",
    "```\n",
    "If the doctests pass, then there should be *no* output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test your code!\n",
    "lab.consecutive_ints([1,3,2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.consecutive_ints([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.consecutive_ints([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5//2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 1 (median and average):**\n",
    "\n",
    "Write a function called *median_vs_average* that takes a non-empty list of numbers and returns True if median is greater or equal than average and False otherwise. \n",
    "\n",
    "To find median: If the list has even length, it should calculate the mean of the two elements in the middle. Do not use any imported libraries for this question; you may use any built-in function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.median_vs_average([6, 5, 4, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.median_vs_average([50, 20, 15, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.median_vs_average([20,20,20,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.median_vs_average([0, -1, 1, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 2 (List Distances):**\n",
    "\n",
    "Similar to Question 0, write a function that takes in a possibly empty list of integers and:\n",
    "* Returns `True` if there exist two list elements $i$ places apart, whose distance as integers is also $i$.\n",
    "* Otherwise, returns `False`.\n",
    "\n",
    "Assume your inputs tend to satisfy the condition, and the pair(s) saitifying the condition tend to be close together; design your function to run faster for this case. (Optimizing your code for an assumed distribution of incoming data is very common in data science).\n",
    "\n",
    "For example, because `3` and (the second) `5` are two places apart, and $|3-5| = 2$:\n",
    "```\n",
    ">>> lab.same_diff_ints([5,3,1,5,9,8])\n",
    "True\n",
    "```\n",
    "Whereas:\n",
    "```\n",
    ">>> lab.same_diff_ints([1,3,5,7,9])\n",
    "False\n",
    "```\n",
    "\n",
    "*Note*: Make sure to define some extreme test cases. Use the `%time` command to time your function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(len([1,2])):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1]\n",
    "x.append(2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.same_diff_ints([1,4,2,8,2,9,3,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.2 ms, sys: 470 µs, total: 18.7 ms\n",
      "Wall time: 18.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time lab.same_diff_ints(long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Strings and Files\n",
    "\n",
    "The following questions will help you (re)learn the basics of working with strings and reading data from files (which are read in as strings, by default)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 3 (N Prefixes):**\n",
    "\n",
    "Write a function `n_prefixes` that takes a string and a positive interger `n`. It returns a string of the first `n` number consecutive prefixes of the input string in reverse order. For example, `n_prefixes('Data!', 3)` should return `'DatDaD'`.  (See the doctests for more examples).\n",
    "\n",
    "Recall that [strings may be sliced](https://docs.python.org/3/tutorial/introduction.html#strings), like lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,0,-1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'abcd'\n",
    "x[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'luclul'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.n_prefixes('lucky', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Question 4 (Exploded numbers):**  \n",
    "\n",
    "Write a function `exploded_numbers` that takes in a list of integers and a non-negative integer $N$ and returns a list of strings containing numbers from the list expanded by N digits to both directions, separated by spaces.\n",
    "\n",
    "Additionally, [zero pad](https://www.tutorialspoint.com/python/string_zfill.htm) each integer, so that each has the same length.\n",
    "\n",
    "For example:\n",
    "\n",
    "```\n",
    ">>> lab.exploded_numbers([3, 4], 2)\n",
    "['1 2 3 4 5', '2 3 4 5 6']\n",
    ">>> lab.exploded_numbers([3, 8, 15], 2)\n",
    "['01 02 03 04 05', '06 07 08 09 10', '13 14 15 16 17']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2, -1, 0, 1, 2]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list(range(-2,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "a + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['001 002 003 004 005', '006 007 008 009 010', '198 199 200 201 202']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.exploded_numbers([3, 8, 200], 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "[Recall](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files) that the built-in function `open` takes in a file path and returns *a file object* (sometimes called a *file handle*). Below are a few properties of file objects:\n",
    "\n",
    "* `open(path)` opens the file at location `path` for reading.\n",
    "* `open(path)` is an *iterable*, which contains successive lines of the file.\n",
    "* Once a file object is opened, after use it should be closed to avoid memory leaks. To ensure a file is closed once done, you should use a *context manager* as follows:\n",
    "```\n",
    "with open(path) as fh:\n",
    "    for line in fh:\n",
    "        process_line(line)\n",
    "```\n",
    "* To read the entire file into a string, use the read method:\n",
    "```\n",
    "with open(path) as fh:\n",
    "    s = fh.read()\n",
    "```\n",
    "However, you should be careful when reading an entire file into memory that the file isn't too big! *You should avoid this whenever possible!*\n",
    "\n",
    "**Question 5 (Reading Files):**\n",
    "\n",
    "Create a function `last_chars` that takes a file object and returns a string consisting of the last character of each line.\n",
    "\n",
    "*Remark:* A newline is the \"delimiter\" of the lines of a file, and doesn't count as part of the line (as the tests imply). Every other character is part of the line. For more info on this, see [the interpretation](https://en.wikipedia.org/wiki/Newline#Interpretation) of files as a 'newline delimited variables' file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "r\n",
      "g\n"
     ]
    }
   ],
   "source": [
    "fp = os.path.join('data', 'chars.txt')\n",
    "with open(fp) as fh:\n",
    "    for line in fh:\n",
    "        print(line[-1-1])\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hrg'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.last_chars(open(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## `numpy` exercises\n",
    "\n",
    "For an introduction to arrays and `numpy` recall the relevant section of [DSC 10](https://www.inferentialthinking.com/chapters/05/1/Arrays.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6 (Basic Arrays):**\n",
    "\n",
    "Create the following functions using `numpy` methods satisfying the requirements given in each part. Your solutions should **not** contain any loops or list comprehensions.\n",
    "\n",
    "* A function `arr_1` that takes in a `numpy` array and adds to each element the square-root of the index of each element.\n",
    "\n",
    "* A function `arr_2` that takes in a `numpy` array of integers and returns a boolean array (i.e. an array of booleans) whose `ith` element is `True` if and only if the `ith` element of the input array is a perfect square.\n",
    "\n",
    "* A function `arr_3` that takes in a `numpy` array of [stock prices](https://en.wikipedia.org/wiki/Stock) per share on successive days in USD and returns an array of growth rates. That is, the `ith` number of the output array should contain the rate of growth in stock price between the $i^{th}$ day to the $(i+1)^{th}$ day. The growth rate should be a proportion, rounded to the nearest hundredth.\n",
    "\n",
    "* Suppose:\n",
    "    - `A` is a `numpy` array of [stock prices](https://en.wikipedia.org/wiki/Stock) per share for a company on successive days in USD \n",
    "    - You start each day with \\\\$20 to buy as much stock as possible on that day. \n",
    "    - Any money left-over after a given day is saved for possibly buying stock on a future day. \n",
    "    - Create a function `arr_4` that takes in `A` and returns the day on which you can buy at least one share from 'left-over' money. If this never happens, return `-1`. The first stock purchase occurs on day 0. *Note: you cannot buy fractions of a share of stock*.\n",
    "    \n",
    "    - *Example:* If the stock price is \\\\$3 every day, then the answer is 'day 1':\n",
    "        - day 0: buy six stocks with \\\\$20, \\\\$2 are added to the leftover, and your total leftover is currently \\\\$2,  so you can't buy one extra share\n",
    "        - day 1: buy six stocks with \\\\$20, another \\\\$2 are added to the leftover, and your total leftover is now \\\\$4, so you can now buy one extra share, return day1.\n",
    "    - Hint: `np.cumsum` may be helpful for this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'stocks.csv')\n",
    "stocks = np.array([float(x) for x in open(fp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = lab.arr_3(stocks)\n",
    "isinstance(out, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numbers\n",
    "stocks = np.array([4,5, 3, 5,7])\n",
    "out = lab.arr_4(stocks)\n",
    "isinstance(out, numbers.Integral)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.dtype == np.dtype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.dtype == np.dtype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'stocks.csv')\n",
    "stocks = np.array([float(x) for x in open(fp)])\n",
    "out = lab.arr_3(stocks)\n",
    "isinstance(out, np.ndarray)\n",
    "#out.dtype == np.dtype('float')\n",
    "#out.max() == 0.03\n",
    "#out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026605504587155885"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.        , 2.44948974, 2.64575131])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.sqrt(A)\n",
    "y[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Getting Started with Pandas\n",
    "\n",
    "The following questions will help you get comfortable with Pandas. These questions are similar to questions on tables in DSC 10; review the [textbook](https://www.inferentialthinking.com) as necessary. As always for Pandas questions:\n",
    "1. Avoid writing loops through the rows of the dataset to do the problem, and\n",
    "2. Test the output/correctness of your code with the help of the dataset given, but be sure your code will also run on data \"like\" the dataset given (sampling rows using the `.sample` method is useful for this!).\n",
    "\n",
    "**Question 7 (Pandas basics):**   \n",
    "\n",
    "Read in the file `salary.csv` in the `data` directory which contains the salary information for the 2017-2018 NBA season and understand the dataset by answering the following questions. To do this, create a function `salary_stats` that takes in a dataframe like `salary` and returns a series containing the following statistics:\n",
    "* The number of players (`num_players`).\n",
    "* The number of teams (`num_teams`).\n",
    "* The total salary amount over the season (`total_salary`).\n",
    "* The name of the player with the highest salary; there are no ties (`highest_salary`).\n",
    "* The average salary of the Boston Celtics ('BOS'), rounded to the nearest hundredth (`avg_bos`).\n",
    "* The name of player and the name of the team whose salary is the third-lowest, separated by a comma and a space (e.g. John Doe, MIA); if there are ties, return the first based on alphabetical order (`third_lowest`).\n",
    "* Whether there are any duplicate last names (True: yes, False: no), as a boolean (`duplicates`).\n",
    "* The total salary of the team that has the highest paid player (`total_highest`).\n",
    "\n",
    "The index of the output series are given in parenthesis above.\n",
    "\n",
    "*Note*: Your function should work on a dataset of the same format that contains information from other years. You may assume that none of the answers involving ranking returns a tie.\n",
    "\n",
    "*Note*: To make sure your function still runs, in the event that one of the 8 parts throws an exception (e.g. due to a very incorrect answer), use `Try... Except...` structures. Here's a useful link: https://www.w3schools.com/python/python_try_except.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_fp = os.path.join('data', 'salary.csv')\n",
    "salary = pd.read_csv(salary_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary['Team'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137494845.0"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = salary['Salary'].unique()\n",
    "t.sort()\n",
    "highest_salary = t[len(t)-1]\n",
    "highTable = salary[salary['Salary'] == highest_salary]\n",
    "highTeam = highTable['Team'].iloc[0]\n",
    "salary[salary['Team'] == highTeam]['Salary'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = lab.salary_stats(salary)\n",
    "#isinstance(out, pd.Series)\n",
    "#    True\n",
    "#'total_highest' in out.index\n",
    " #   True\n",
    "#isinstance(out.loc['duplicates'], bool)\n",
    "#    True\n",
    "#out['duplicates'].dtype\n",
    "#out.loc['duplicates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Axel Toupane, NOP'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LowTable = salary[salary['Salary'] == thirdLow]\n",
    "#sort player alphabetically\n",
    "fst = LowTable.sort_values(by = ['Player']).iloc[0]\n",
    "result = fst['Player'] + ',' + ' ' + fst['Team']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Jarell Eddie</td>\n",
       "      <td>CHI</td>\n",
       "      <td>17224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Joel Bolomboy</td>\n",
       "      <td>MIL</td>\n",
       "      <td>22248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Axel Toupane</td>\n",
       "      <td>NOP</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Quinn Cook</td>\n",
       "      <td>NOP</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Beno Udrih</td>\n",
       "      <td>DET</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Blake Griffin</td>\n",
       "      <td>DET</td>\n",
       "      <td>29512900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Gordon Hayward</td>\n",
       "      <td>BOS</td>\n",
       "      <td>29727900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>Paul Millsap</td>\n",
       "      <td>DEN</td>\n",
       "      <td>31269231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>CLE</td>\n",
       "      <td>33285709.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>GSW</td>\n",
       "      <td>34682550.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>573 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player Team      Salary\n",
       "240    Jarell Eddie  CHI     17224.0\n",
       "269   Joel Bolomboy  MIL     22248.0\n",
       "36     Axel Toupane  NOP     25000.0\n",
       "442      Quinn Cook  NOP     25000.0\n",
       "40       Beno Udrih  DET     25000.0\n",
       "..              ...  ...         ...\n",
       "42    Blake Griffin  DET  29512900.0\n",
       "193  Gordon Hayward  BOS  29727900.0\n",
       "437    Paul Millsap  DEN  31269231.0\n",
       "344    LeBron James  CLE  33285709.0\n",
       "495   Stephen Curry  GSW  34682550.0\n",
       "\n",
       "[573 rows x 3 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary.sort_values(by = ['Salary'], ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## CSV Files\n",
    "**Question 8 (Reading malformed csv files):**\n",
    "\n",
    "`malformed.csv` contains a file of comma-separated values, containing the following fields:\n",
    "\n",
    "\n",
    "|column name|description|type|\n",
    "|---|---|---|\n",
    "|first|first name of person|str|\n",
    "|last|last name of person|str|\n",
    "|weight|weight of person (lbs)|float|\n",
    "|height|height of person (in)|float|\n",
    "|geo|location of person; comma-separated latitude/longitude|str|\n",
    "\n",
    "Unfortunately, the entries contains errors that cause the Pandas `read_csv` function to fail parsing the file with the default settings. Instead, you must read in the file manually using Python's built-in `open` function.\n",
    "\n",
    "Clean the csv file into a Pandas DataFrame with columns as described in the table above, by creating a function called `parse_malformed` that takes in a file path and returns a parsed, properly-typed dataframe. The dataframe should contain columns as described in the table above (with the specified types); it should agree with `pd.read_csv` when the lines are not malformed.\n",
    "\n",
    "\n",
    "*Note:* Assume that the given csv file is a sample of a larger file; you will be graded against a **different** sample of the larger file that has the same type of parsing errors. That is, you should **not** hard-code your cleaning of the data to specific errors on specific lines in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'malformed.csv')\n",
    "df = lab.parse_malformed(fp)\n",
    "cols = ['first', 'last', 'weight', 'height', 'geo']\n",
    "#list(df.columns) == cols\n",
    "#    True\n",
    "#df['last'].dtype == np.dtype('O')\n",
    " #   True\n",
    "#df['height'].dtype == np.dtype('float64')\n",
    " #   True\n",
    "#df['geo'].str.contains(',').all()\n",
    " #   True\n",
    "#len(df) == 100\n",
    " #   True\n",
    "dg = pd.read_csv(fp, nrows=4, skiprows=10, names=cols)\n",
    "dg.index = range(9, 13)\n",
    "(dg == df.iloc[9:13]).all().all()\n",
    "#    True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done!\n",
    "\n",
    "* Submit the lab on Gradescope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
