{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Messy Data and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "* Data Generating Processes.\n",
    "* Introduction to field types.\n",
    "* Outliers: how to spot them and fix them.\n",
    "* Missing values: understanding them and dropping them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## There is no such thing as 'raw data'.\n",
    "\n",
    "* Data are the result of measurements that must be recorded.\n",
    "* Humans design the measurements and record the results.\n",
    "* Data is *always* an imperfect record of the underlying processing being measured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Generating Process\n",
    "\n",
    "* A **data generating process** is the underlying, real-world (probabilistic) mechanism that generates the observed data. \n",
    "* Observed data is an incomplete artifact of the data generating process.\n",
    "* A data generating process is what a statistical model attempts to describe.\n",
    "\n",
    "Cleaning data requires understanding of the data generating process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Unemployment Data\n",
    "* Problem: predict the effect policy X has on the US labor market\n",
    "    - Does it decrease unemployment? Increase wages?\n",
    "* Data: [labor force data](https://www.bls.gov/cps/cps_htgm.pdf) collected by the BLS (U.S. Bureau of Labor Statistics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Unemployment Data\n",
    "* Sample quality: Is the BLS data a sample or census?\n",
    "* Measurement; who is counted as:\n",
    "    - employed? unemployed? underemployed? not in the labor force?\n",
    "* The data are generated according to a *political* process!\n",
    "    - For an introduction, see [this article](https://www.nytimes.com/2018/09/14/opinion/columnists/great-recession-economy-gdp.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Provenance: can I trust my data?\n",
    "\n",
    "Understanding as much as possible about the lineage of data from \n",
    "1. The assumptions on the data generating process, to\n",
    "2. the initial measurements of that (or a similar) process, to  \n",
    "3. the data in its eventually acquired form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Cleaning\n",
    "\n",
    "* The process of transforming data:\n",
    "    - into a faithful representation of an underlying data generating process \n",
    "    - to facilitate subsequent analysis.\n",
    "\n",
    "* In practice, data cleaning is often detective work to understand data provenance.\n",
    "    - **always be skeptical of your data!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data cleaning often addresses:\n",
    "\n",
    "* The structure of the recorded data \n",
    "    - are the individual properly represented as rows?\n",
    "* The encoding and format of the values in the data.\n",
    "    - are the data types of a column reflective of the information it contains?\n",
    "* Corrupt and \"incorrect\" data; missing values.\n",
    "    - were their flaws in the 'data recording process'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"imgs/image_2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion: are each of the following Quantitative, Ordinal, or Nominal?\n",
    "\n",
    "1. **Price in dollars of a product?**\n",
    "1. **Star Rating on Yelp?**\n",
    "1. **Date/time an item was sold?**\n",
    "1. **Day of the week an item was sold?**\n",
    "1. **A Credit Card Number?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Answers:\n",
    "\n",
    "|Question|Answer|\n",
    "|---|---|\n",
    "|Price in dollars of a product|Quantitatave|\n",
    "|Star Rating on Yelp|Ordinal|\n",
    "|Date an item was sold|Quantitative|\n",
    "|Day of week an item was sold|????|\n",
    "|Credit Card Number|Nominal|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Converting data types in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student dataset\n",
    "- **Student ID, Student Name** (should be clear)\n",
    "- **Month, Day, Year**: date when student was accepted to UCSD\n",
    "- **2018, 2019 tuitions and growth** (should be clear)\n",
    "- **Paid**: Indicates if tuition is paid yet\n",
    "- **DSC80 Final grade**: Some students may take class for Pass/Fail\n",
    "\n",
    "What needs to be changed in the dataframe to compute statistics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is the sum of tuition paid in 2018 and 2019?\n",
    "* Sum tuition columns using `+`\n",
    "* Save it in a `pd.Series` called `total`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series => Array arithmetic\n",
    "total = df['2018 tuition'] + df['2019 tuition']\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Check the data types of the student table\n",
    "* What data type *should* each column have?\n",
    "* What kinds of data should each column have?\n",
    "    - Quantitative, Catgorical (Ordinal, Nominal)\n",
    "* Use the `df.dtypes` attribute to peak at the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cleaning up: `Student ID`\n",
    "\n",
    "* `Student ID` is a `float64`, should be `int64`\n",
    "* May be a float value due to earlier processing with e.g. Excel.\n",
    "* Change the type using `.astype` method\n",
    "    - `.astype` returns a copy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column reassignment\n",
    "df['Student ID'] = df['Student ID'].astype(np.int64)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cleaning up: `20xx tuition`\n",
    "\n",
    "* `20xx tuition` are stored as `objects` (strings), not numerical values.\n",
    "* The formatting character ($) causes the entries to be interpreted as strings.\n",
    "* Use `str` methods to strip the dollar sign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try this!\n",
    "df['2018 tuition'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip the $\n",
    "# use .str to access Python string methods\n",
    "df['2018 tuition'].str.strip('$').astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looping through *columns* is ok! don't loop through rows.\n",
    "\n",
    "for col in df.columns:\n",
    "    if 'tuition' in col:\n",
    "        df[col] = df[col].str.strip('$').astype(np.float64)\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cleaning up: `Paid`\n",
    "\n",
    "* The `Paid` column should be either `bool` type, or {0,1}.\n",
    "* Y/N typical values from human entry.\n",
    "* Use the `replace` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Paid'] = df['Paid'].replace({'Y': True, 'N': False})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cleaning up: `Month, Day, and Year`\n",
    "* Each are `int64` types; this could be *fine* for certain purposes.\n",
    "* Could store as `objects` of the form `Year-Month-Day`\n",
    "    - String sorting coincides with date sorting\n",
    "* Could store as `datetime64` objects (later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is happening with adding a Series and a string? (Broadcasting)\n",
    "(\n",
    "    df['Year'].astype(str) + '-' + \n",
    "    df['Month'].astype(str).str.zfill(2) + '-' + \n",
    "    df['Day'].astype(str).str.zfill(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cleaning up: `DSC 80 Final Grade`\n",
    "\n",
    "* `DSC 80 Final Grade` stored as an object.\n",
    "    - most entries should be numeric;\n",
    "    - final entry cannot be converted.\n",
    "* Can use `pd.to_numeric(Series, errors='coerce')`.\n",
    "    - Be careful with this!\n",
    "    - `errors='coerce'` can cause uninformed destruction of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try: astype\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DSC 80 Final Grade'] = pd.to_numeric(df['DSC 80 Final Grade'], errors='coerce')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cleaning up: `Student Name`\n",
    "* Need the `Student Name` column to have form **Last Name, First Name**.\n",
    "* Use a custom function and the `apply` method.\n",
    "    - `Series.apply(func)` applies the function `func` to each entry of `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Student Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_name(name):\n",
    "    firstname, lastname = name.split()\n",
    "    return lastname + ', ' + firstname\n",
    "\n",
    "transpose_name('Aaron Fraenkel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Student Name'].apply(transpose_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More data type ambiguities\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "1. 1537660383 looks like a number, but is probably a date (Unix timestamp, seconds since 1970)\n",
    "\n",
    "2. \"USD 1,000,000\" looks like a string, but is actually a number and a unit.\n",
    "\n",
    "3. 02111 looks like a number, but is really a zip code (and isn't equal to 2,111)\n",
    "\n",
    "<img src=\"imgs/image_3.png\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How well does the data capture \"reality\"\n",
    "\n",
    "* Does my data contain unrealistic or \"incorrect\" values?\n",
    "    - Dates in the future for events in the past\n",
    "    - Locations that don't exist\n",
    "    - Negative counts\n",
    "    - Misspellings of names\n",
    "    - Large outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How well does the data capture \"reality\"\n",
    "\n",
    "    \n",
    "* Does my data violate obvious dependencies?\n",
    "    - E.g., age and birthday don't match \n",
    "    \n",
    "\n",
    "* Was the data entered by hand?\n",
    "     - Spelling errors, fields shifted …\n",
    "     - Did the form require fields or provide default values?\n",
    "     \n",
    "* Are there obvious signs of curb stoning (data falsification):\n",
    "    - Repeated names, fake looking email addresses, repeated use of uncommon names or fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vehicle Stop Data. Practical Example\n",
    "\n",
    "## Data Source\n",
    "\n",
    "<img src=\"imgs/image_4.png\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Police Vehicle Stops\n",
    "\n",
    "Vehicle stops made by the San Diego Police Department. \n",
    "\n",
    "Vehicle Stops files contain all vehicle stops for a given year.\n",
    "\n",
    "<img src=\"imgs/image_5.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# SDPD Vehicle Stop Data\n",
    "\n",
    "\n",
    "### Identifying messy data, general questions. \n",
    "\n",
    "1. Check the data types, notice any issues? What should we do?\n",
    "2. String type fields have consistent values?\n",
    "3. No missing values that we don't understand?\n",
    "4. Are all values look in a reasonable range?\n",
    "5. How do we deal with the messiness we found?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'Vehicle_stops_2016_datasd.csv')\n",
    "stops = pd.read_csv(fp)\n",
    "stops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### SDPD vehicle stops: data types\n",
    "* Are the data types correct?\n",
    "* Are they easily fixable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are the data types correct? How to fix them?\n",
    "stops.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### SDPD vehicle stops: unfaithfulness\n",
    "* Are there suspicious values?\n",
    "* If a value is suspicious, can we trust the observation?\n",
    "* Age: Nonsensical? Too old? Too young?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops['subject_age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = pd.to_numeric(stops['subject_age'], errors='coerce')\n",
    "ages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows? change age value to null? Is there really a 220 year old? (investigate!)\n",
    "stops[(ages > 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages.loc[lambda x:(0<=x) & (x<16)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops[(0 < ages) & (ages < 16)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### SDPD data: unfaithful `subject_age`\n",
    "\n",
    "* Values of 'No Age' and 0 likely explicit null values\n",
    "* Unusually small/large ages errors in data entry?\n",
    "    - Rest of record is well formed.\n",
    "* Hard to tell for ages 14,15.\n",
    "    - Each has more than one occurance; possibly real?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### SDPD vehicle stops: human entered data\n",
    "* Which fields were likely entered by a human?\n",
    "* Which fields were likely generated by code?\n",
    "    - what was the original source?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop cause\n",
    "stops.stop_cause.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age distribution -- reasonable ages (e.g. 15-85)\n",
    "ages.loc[lambda x:(x > 15) & (x<=85)].plot(kind='hist', bins=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computer generated?\n",
    "stops[['timestamp', 'stop_date', 'stop_time']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops[['timestamp', 'stop_date', 'stop_time']].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unfaithful data vs Outliers\n",
    "\n",
    "* Unfaithful data are data that doesn't accurately represent the data generating processing being measured.\n",
    "* Outliers are \"ununsual\" observations, unlike the rest of the data. They may be unfaithful, but they may be real (and interesting) as well! \n",
    "* The two are hard to tell apart; doing so often requires research and/or domain expertise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outliers\n",
    "\n",
    "* **Consistently \"nonsense\" values**\n",
    "    - Is it a product of the data ingestion process? Time field has year 1899? Is it an inferred “default” value?\n",
    "    - Solution: Change the value to the correct one!\n",
    "    \n",
    "* **Abnormal artifacts from the data collection process**\n",
    "    - E.g. unreasonable spikes in recorded ages at round numbers (25, 35, 45)\n",
    "    - Solution: Try \"smoothing\" (e.g. binning the ages)\n",
    "        \n",
    "* **Unreasonable outliers**\n",
    "    - Data points with unrealistic and highly unreasonable values. E.g. age = 200\n",
    "    - Solution: filter it? Maybe it points to bugs in the data collection? Maybe it's real and you should investigate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Missing Values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Many reasons for missing values\n",
    "\n",
    "* Missing values in a dataset can occur from:\n",
    "    - Intentional logic, where a value doesn't make sense.\n",
    "    - A non-response in the measurement process.\n",
    "    - Mistakes in the recording process\n",
    "    - ...\n",
    "    \n",
    "* Missing values are most often encoded with:\n",
    "    - `NULL`, `None`, `NaN`, `\"\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Missing values come in many forms\n",
    "\n",
    "* Missing values can appear as 'placeholder' values:\n",
    "    - All forms of `0` are a common substitute for null.\n",
    "    - -1 is column if a column must be non-negative.\n",
    "    - 1900 and 1970 if a nonnull date is required.  (Excel and Unix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Missing values come in many forms\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "* These 'Missing Values' may be possible 'real' values!\n",
    "* \"Null Island\" at 0°00'00.0\"N+0°00'00.0\"E\n",
    "    - Null Island a popular jogging location on Strava fitness tracking app.\n",
    "    - https://en.wikipedia.org/wiki/Null_Island\n",
    "\n",
    "<img src=\"imgs/image_6.png\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Messy missingness in vehicle stops data\n",
    "* What are the non-`NaN` null values in the SDPD data?\n",
    "    - Service Area: 'Unknown'\n",
    "    - Subject Age: 0\n",
    "    - Others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Handling null values in Pandas\n",
    "\n",
    "* Null values are encoded using NumPy's `NaN` object, which is of float type.\n",
    "* Method `.isnull()` for DataFrame/Series detects missing values.\n",
    "    - returns a boolean DataFrame/Series!\n",
    "* Methods `.dropna()` and `.fillna()` handle missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of people without an age recorded\n",
    "stops.subject_age.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all columns null percentage\n",
    "stops.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling null values: dropping observations\n",
    "* What happens if any row with a null value is dropped?\n",
    "* Best to not drop observations until it's needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of dataset dropped:\n",
    "stops.isnull().any(axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `.dropna` method\n",
    "\n",
    "* `.dropna()` drops rows containing *at least one* null value.\n",
    "* `.dropna(how='all')` drops any row that contains *only* null values.\n",
    "* `.dropna(axis=1)` drops *columns* containing at least one null value.\n",
    "* Other keyword arguments: `thresh`, `subset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans = pd.DataFrame([[0,1,np.NaN], [np.NaN, np.NaN, np.NaN], [1, 2, 3]])\n",
    "nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans.dropna(subset=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.fillna` method\n",
    "\n",
    "* `.fillna(val)` fills null entries with value `val`.\n",
    "* `.fillna(dict)` fills null entries using a dictionary `dict` of column/row values.\n",
    "* `.fillna(method='ffill')` fills null entries using neighboring non-null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill with a fixed value\n",
    "nans.fillna(\"FILLED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill using a column-dictionary\n",
    "nans.fillna({0:'f0', 1:'f1', 2:'f2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill with the column mean\n",
    "means = {c:nans[c].mean() for c in nans.columns}\n",
    "nans.fillna(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backfill up columns\n",
    "nans.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward fill down columns\n",
    "nans.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Data Types and `NaN`\n",
    "\n",
    "* The result of *any* comparison (=,!=,<,>) with `NaN` is `False`.\n",
    "     - Use functions for checking null: `np.isnan`, `np.isnull`\n",
    "* `NaN` is of float-type.\n",
    "* Be careful of Pandas type-coercian with `NaN`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "for x in nans.iloc[0]:\n",
    "    if x == np.NaN:\n",
    "        print(\"it's NaN!\")\n",
    "    else:\n",
    "        print('nope!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "for x in nans.iloc[0]:\n",
    "    if np.isnan(x):\n",
    "        print(\"it's NaN!\")\n",
    "    else:\n",
    "        print('nope!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# series with null: ints are cast as float\n",
    "nans = pd.Series([0,1,np.NaN])\n",
    "nnan = pd.Series([0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# filled in: of float type\n",
    "nans.dtype, nan.dtype"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
